{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7491434",
   "metadata": {},
   "source": [
    "#  Scraper allrecipes\n",
    "### Categoria, Nombre, URL general, Position, URL de cada position, Breadcrumb, Image URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5443cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "def extract_category_urls(url):\n",
    "    # Realizar la solicitud HTTP GET\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parsear el contenido HTML de la respuesta\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Encontrar todos los elementos <div> con la clase \"alphabetical-list__group\"\n",
    "    category_groups = soup.find_all(\"div\", class_=\"alphabetical-list__group\")\n",
    "\n",
    "    category_data = []\n",
    "    for category_group in category_groups:\n",
    "        # Obtener el nombre de la categoría\n",
    "        category_name = category_group.find(\"h3\").text.strip()\n",
    "\n",
    "        # Obtener los elementos <a> de la categoría\n",
    "        category_items = category_group.find_all(\"a\")\n",
    "        for item in category_items:\n",
    "            item_name = item.text.strip()\n",
    "            item_url = item[\"href\"]\n",
    "            category_data.append((category_name, item_name, item_url))\n",
    "\n",
    "    return category_data\n",
    "\n",
    "\n",
    "def extract_breadcrumb_and_image_urls(url):\n",
    "    # Realizar la solicitud HTTP GET a la URL extraída\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parsear el contenido HTML de la respuesta\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Encontrar el elemento <script> que contiene el ld+json\n",
    "    script_tag = soup.find(\"script\", type=\"application/ld+json\")\n",
    "\n",
    "    # Obtener el contenido del elemento <script>\n",
    "    script_content = script_tag.string\n",
    "\n",
    "    # Convertir el contenido a un objeto JSON\n",
    "    data = json.loads(script_content)\n",
    "\n",
    "    # Acceder a la información deseada\n",
    "    main_entity = data[0][\"mainEntityOfPage\"]\n",
    "    breadcrumb_list = main_entity[\"breadcrumb\"][\"itemListElement\"]\n",
    "\n",
    "    breadcrumbs = []\n",
    "    # Obtener el ListItem anterior al último ListItem\n",
    "    if len(breadcrumb_list) >= 2:\n",
    "        penultimate_item = breadcrumb_list[-2]\n",
    "        breadcrumb = penultimate_item.get(\"item\", {}).get(\"@id\", \"\").split(\"https://www.allrecipes.com/recipes/\")[-1].split(\"/\")[1:-1]\n",
    "        if breadcrumb:\n",
    "            breadcrumbs = breadcrumb\n",
    "\n",
    "    # Encontrar todas las etiquetas <img> en la página\n",
    "    img_tags = soup.find_all(\"img\")\n",
    "\n",
    "    # Obtener las URLs de las imágenes\n",
    "    image_urls = [img.get(\"src\") for img in img_tags if img.get(\"src\")]\n",
    "    if image_urls:\n",
    "        image_urls = [image_urls[0]]\n",
    "\n",
    "    return breadcrumbs, image_urls\n",
    "\n",
    "# URL de la página inicial para extraer las categorías\n",
    "initial_url = \"https://www.allrecipes.com/ingredients-a-z-6740416\"\n",
    "\n",
    "# Paso 1: Extraer todas las URL de las categorías y sus nombres\n",
    "category_data = extract_category_urls(initial_url)\n",
    "\n",
    "# Paso 2: Para cada categoría y URL, extraer las URL internas, el Breadcrumb y las URLs de las imágenes\n",
    "all_breadcrumbs = []\n",
    "for category_name, item_name, item_url in category_data:\n",
    "    print(\"Categoría:\", category_name)\n",
    "    print(\"Nombre:\", item_name)\n",
    "    print(\"URL:\", item_url)\n",
    "\n",
    "    # Realizar la solicitud HTTP GET\n",
    "    response = requests.get(item_url)\n",
    "\n",
    "    # Parsear el contenido HTML de la respuesta\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Encontrar el elemento <script> que contiene el ld+json\n",
    "    script_tag = soup.find(\"script\", type=\"application/ld+json\")\n",
    "\n",
    "    # Obtener el contenido del elemento <script>\n",
    "    script_content = script_tag.string\n",
    "\n",
    "    # Convertir el contenido a un objeto JSON\n",
    "    data = json.loads(script_content)\n",
    "\n",
    "    # Acceder a la información deseada\n",
    "    item_list = data[0][\"itemListElement\"]\n",
    "\n",
    "    for item in item_list:\n",
    "        position = item[\"position\"]\n",
    "        url = item[\"url\"]\n",
    "\n",
    "        print(\"Position:\", position)\n",
    "        print(\"URL:\", url)\n",
    "\n",
    "        # Obtener el Breadcrumb y las URLs de las imágenes\n",
    "        breadcrumbs, image_urls = extract_breadcrumb_and_image_urls(url)\n",
    "\n",
    "        if breadcrumbs:\n",
    "            print(\"Breadcrumb:\", breadcrumbs)\n",
    "\n",
    "        if image_urls:\n",
    "            print(\"Image URLs:\", image_urls)\n",
    "\n",
    "        print()\n",
    "\n",
    "        # Descargar las imágenes si se desea\n",
    "        # for i, image_url in enumerate(image_urls):\n",
    "        #     response = requests.get(image_url)\n",
    "        #     with open(f\"image_{position}_{i+1}.jpg\", \"wb\") as f:\n",
    "        #         f.write(response.content)\n",
    "\n",
    "    print()\n",
    "\n",
    "print(\"-----------------------Breadcrumbs:-----------------------\")\n",
    "for breadcrumb in all_breadcrumbs:\n",
    "    print(breadcrumb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
